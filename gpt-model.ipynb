{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gpt-model.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Ls3uck6XSvP6Vn71bRIIvLcm9jgyChvW","authorship_tag":"ABX9TyNL9VwZGzU2cSwcG4omFz3B"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"07f8be0b2da14b5db39baf58dadaea4d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_273c9d8fa9324f8799c89c8adb86e6f3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_399cac96185943ed8f442eae6aa36dd7","IPY_MODEL_d8f8c722f86d4ed88bf9af81de5d321d","IPY_MODEL_e761c9dd7f864dc4987d97408a8a447a"]}},"273c9d8fa9324f8799c89c8adb86e6f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"399cac96185943ed8f442eae6aa36dd7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d95b49d10a334e43a942b703d12a9aab","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b4a8c313ca9346ff9f72324f319bf724"}},"d8f8c722f86d4ed88bf9af81de5d321d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_66b5d513442141f3bdab5044cda057c2","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1042301,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1042301,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_431f59dac9f4492c9f3d17e152e7462b"}},"e761c9dd7f864dc4987d97408a8a447a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1beadbd509644c0b9541839f8eb810e2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0.99M/0.99M [00:00&lt;00:00, 3.21MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_785aff4e9a304e098f37b598a9657fce"}},"d95b49d10a334e43a942b703d12a9aab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b4a8c313ca9346ff9f72324f319bf724":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"66b5d513442141f3bdab5044cda057c2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"431f59dac9f4492c9f3d17e152e7462b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1beadbd509644c0b9541839f8eb810e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"785aff4e9a304e098f37b598a9657fce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bd1e4f034b0c418bae96df657b668000":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f551379a979f4fe7a7e049e36a82c51a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_788921d7bb604f3dac33b5ec464177c2","IPY_MODEL_24620715e6404b0d802a231a38c069ad","IPY_MODEL_957fb81ff0cb474685f668d56f1b7345"]}},"f551379a979f4fe7a7e049e36a82c51a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"788921d7bb604f3dac33b5ec464177c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_84d32566089c4dcf93826dab97ee44ec","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c0b905c6097b460b8c25eaa8212058f9"}},"24620715e6404b0d802a231a38c069ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6584502d55674496b76c63bee7dbd391","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b8964ddd8ee84a69aa5c8f07c81304cb"}},"957fb81ff0cb474685f668d56f1b7345":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9e6fea2655a44c5da4f84f2d4388fb18","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 446k/446k [00:00&lt;00:00, 871kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d5f703c826de4251960ec305d122e2ee"}},"84d32566089c4dcf93826dab97ee44ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c0b905c6097b460b8c25eaa8212058f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6584502d55674496b76c63bee7dbd391":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b8964ddd8ee84a69aa5c8f07c81304cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9e6fea2655a44c5da4f84f2d4388fb18":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d5f703c826de4251960ec305d122e2ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"585bcd1a9d4e42a097a51daeef20091b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7e5a74367235470782a500d78967a554","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0857643480554baa82140ccae0cbc7e8","IPY_MODEL_5399e7c85578467389e33bbb1edde564","IPY_MODEL_b32cac83eab141999db92c083a5beec2"]}},"7e5a74367235470782a500d78967a554":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0857643480554baa82140ccae0cbc7e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f40aa6dc051043bebbb062733e5a616f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c0a70d887d374e8a909bc87bade183a4"}},"5399e7c85578467389e33bbb1edde564":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_757697fd5a63403f8f8eabf0a50c55b8","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1355256,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355256,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8a2f7fc0b1ae4af9956e334002ee0338"}},"b32cac83eab141999db92c083a5beec2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a5b08c6143bc4ec18c6ac59730397fb1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.29M/1.29M [00:00&lt;00:00, 2.79MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4439bbe0c0e6416292c3793a13a1b67d"}},"f40aa6dc051043bebbb062733e5a616f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c0a70d887d374e8a909bc87bade183a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"757697fd5a63403f8f8eabf0a50c55b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8a2f7fc0b1ae4af9956e334002ee0338":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a5b08c6143bc4ec18c6ac59730397fb1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4439bbe0c0e6416292c3793a13a1b67d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"639c63c74f2d42b78297689b47ab87a2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_87f46d49224742849ef66c2ee0012f0e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ab4a22b32b714a47809b22ff4bc44f38","IPY_MODEL_1c68b7cbd86f44459210de68cd3340e0","IPY_MODEL_8a8e68d6f7524bd6ab546abe1a323666"]}},"87f46d49224742849ef66c2ee0012f0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ab4a22b32b714a47809b22ff4bc44f38":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5bb1f720ba444ab188976ae180f79f10","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8f80108ca03a4c828aaca7505c7ae20f"}},"1c68b7cbd86f44459210de68cd3340e0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_08520c1d6c46424b9e6591854a4978d9","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":665,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":665,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_04fda46ebd684bbf8759d10fc4e716a1"}},"8a8e68d6f7524bd6ab546abe1a323666":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2a15488ea2eb4ad9bfbb01627ce9d97d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 665/665 [00:00&lt;00:00, 12.8kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1f8b98c8a0be42d9bbf0799cc793ed0b"}},"5bb1f720ba444ab188976ae180f79f10":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8f80108ca03a4c828aaca7505c7ae20f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"08520c1d6c46424b9e6591854a4978d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"04fda46ebd684bbf8759d10fc4e716a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2a15488ea2eb4ad9bfbb01627ce9d97d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1f8b98c8a0be42d9bbf0799cc793ed0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78de7cfc5c24466cad2f0aae443c7030":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_26467709df644325a3f8c73408a119a7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_44cb344b97ff4f1d8857c3f907249b64","IPY_MODEL_e72dd7f7e1364bc7af36336a985b268a","IPY_MODEL_86019dfe26044f2c9d374e8540d2e3a6"]}},"26467709df644325a3f8c73408a119a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"44cb344b97ff4f1d8857c3f907249b64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c97a91ffa1684e4aa8ceebd7b0812f8e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_66a51cc0fb9941bcbc13abb26eeb28df"}},"e72dd7f7e1364bc7af36336a985b268a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7077fd52aa0745a6b5f3fd42c7f37fdc","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":548118077,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":548118077,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_496250d4875b4acdab721b006f04dee7"}},"86019dfe26044f2c9d374e8540d2e3a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_387e08e07c0844a6b5d040ccac6c5905","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 523M/523M [00:25&lt;00:00, 22.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b668c98444b64e83974f7594253de886"}},"c97a91ffa1684e4aa8ceebd7b0812f8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"66a51cc0fb9941bcbc13abb26eeb28df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7077fd52aa0745a6b5f3fd42c7f37fdc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"496250d4875b4acdab721b006f04dee7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"387e08e07c0844a6b5d040ccac6c5905":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b668c98444b64e83974f7594253de886":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WgllOqZGjsnE","executionInfo":{"status":"ok","timestamp":1637818385637,"user_tz":-300,"elapsed":8314,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"11d7ce37-950a-4c9d-89e8-4660695c9ffa"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 7.9 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 54.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 37.2 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 7.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 56.6 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["07f8be0b2da14b5db39baf58dadaea4d","273c9d8fa9324f8799c89c8adb86e6f3","399cac96185943ed8f442eae6aa36dd7","d8f8c722f86d4ed88bf9af81de5d321d","e761c9dd7f864dc4987d97408a8a447a","d95b49d10a334e43a942b703d12a9aab","b4a8c313ca9346ff9f72324f319bf724","66b5d513442141f3bdab5044cda057c2","431f59dac9f4492c9f3d17e152e7462b","1beadbd509644c0b9541839f8eb810e2","785aff4e9a304e098f37b598a9657fce","bd1e4f034b0c418bae96df657b668000","f551379a979f4fe7a7e049e36a82c51a","788921d7bb604f3dac33b5ec464177c2","24620715e6404b0d802a231a38c069ad","957fb81ff0cb474685f668d56f1b7345","84d32566089c4dcf93826dab97ee44ec","c0b905c6097b460b8c25eaa8212058f9","6584502d55674496b76c63bee7dbd391","b8964ddd8ee84a69aa5c8f07c81304cb","9e6fea2655a44c5da4f84f2d4388fb18","d5f703c826de4251960ec305d122e2ee","585bcd1a9d4e42a097a51daeef20091b","7e5a74367235470782a500d78967a554","0857643480554baa82140ccae0cbc7e8","5399e7c85578467389e33bbb1edde564","b32cac83eab141999db92c083a5beec2","f40aa6dc051043bebbb062733e5a616f","c0a70d887d374e8a909bc87bade183a4","757697fd5a63403f8f8eabf0a50c55b8","8a2f7fc0b1ae4af9956e334002ee0338","a5b08c6143bc4ec18c6ac59730397fb1","4439bbe0c0e6416292c3793a13a1b67d","639c63c74f2d42b78297689b47ab87a2","87f46d49224742849ef66c2ee0012f0e","ab4a22b32b714a47809b22ff4bc44f38","1c68b7cbd86f44459210de68cd3340e0","8a8e68d6f7524bd6ab546abe1a323666","5bb1f720ba444ab188976ae180f79f10","8f80108ca03a4c828aaca7505c7ae20f","08520c1d6c46424b9e6591854a4978d9","04fda46ebd684bbf8759d10fc4e716a1","2a15488ea2eb4ad9bfbb01627ce9d97d","1f8b98c8a0be42d9bbf0799cc793ed0b","78de7cfc5c24466cad2f0aae443c7030","26467709df644325a3f8c73408a119a7","44cb344b97ff4f1d8857c3f907249b64","e72dd7f7e1364bc7af36336a985b268a","86019dfe26044f2c9d374e8540d2e3a6","c97a91ffa1684e4aa8ceebd7b0812f8e","66a51cc0fb9941bcbc13abb26eeb28df","7077fd52aa0745a6b5f3fd42c7f37fdc","496250d4875b4acdab721b006f04dee7","387e08e07c0844a6b5d040ccac6c5905","b668c98444b64e83974f7594253de886"]},"id":"SlK1OMIklSIh","executionInfo":{"status":"ok","timestamp":1637818455214,"user_tz":-300,"elapsed":42201,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"98ebb539-6e48-41fc-84f6-19e4792a12c3"},"source":["import torch\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","model = GPT2LMHeadModel.from_pretrained('gpt2')\n","\n","inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n","outputs = model(**inputs, labels=inputs[\"input_ids\"])\n","loss = outputs.loss\n","logits = outputs.logits"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07f8be0b2da14b5db39baf58dadaea4d","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd1e4f034b0c418bae96df657b668000","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"585bcd1a9d4e42a097a51daeef20091b","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"639c63c74f2d42b78297689b47ab87a2","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78de7cfc5c24466cad2f0aae443c7030","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PkcL9Lrila18","executionInfo":{"status":"ok","timestamp":1637818467174,"user_tz":-300,"elapsed":392,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"9277b80f-b746-49e7-8a06-d30459bd3cfc"},"source":["logits"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ -35.2362,  -35.3266,  -38.9753,  ...,  -44.4645,  -43.9974,\n","           -36.4580],\n","         [-112.6171, -114.5831, -116.5724,  ..., -119.0128, -118.8059,\n","          -111.6917],\n","         [ -88.7435,  -89.8643,  -93.1977,  ...,  -92.3839,  -96.1782,\n","           -92.1273],\n","         [ -85.1646,  -88.3379,  -92.8703,  ...,  -99.8017,  -94.7657,\n","           -90.9330],\n","         [-116.7280, -119.3950, -121.7259,  ..., -129.1003, -124.6102,\n","          -121.6092],\n","         [ -77.4425,  -80.4462,  -88.0497,  ...,  -96.2564,  -93.6345,\n","           -84.0666]]], grad_fn=<UnsafeViewBackward0>)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZN30f53Zln-G","executionInfo":{"status":"ok","timestamp":1637818630477,"user_tz":-300,"elapsed":415,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"3abbea92-f6c0-4108-f123-9e3cccc8b849"},"source":["loss"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(3.9902, grad_fn=<NllLossBackward0>)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r2Q8qZjYmL--","executionInfo":{"status":"ok","timestamp":1637818789846,"user_tz":-300,"elapsed":363,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"1d5ca408-4534-4e73-c8d5-0680674dd858"},"source":["outputs.values"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function CausalLMOutputWithCrossAttentions.values>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"yxc6pkFNoA2V"},"source":["inp = tokenizer('Hello are you ready for fight?')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HEATkErqp9Hg","executionInfo":{"status":"ok","timestamp":1637819621967,"user_tz":-300,"elapsed":369,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"bedf433b-943f-44c7-9da4-ef520e0cab86"},"source":["inp.input_ids"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[15496, 389, 345, 3492, 329, 1907, 30]"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"LZPlLoL4P4C3"},"source":["## Title generator"]},{"cell_type":"code","metadata":{"id":"ADvjztjbP1NW"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import string\n","import urllib.request\n","import pickle\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vTehCkO_RNVZ"},"source":["import csv\n","import itertools\n","import operator\n","import nltk\n","import sys\n","from datetime import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VsVWJmrPP1QN"},"source":["def download_data(url, save_location):\n","    \"\"\"\n","    Download data to be used as corpus\n","    \"\"\"\n","    print('Beginning file download...')  \n","    urllib.request.urlretrieve(url,save_location)\n","    print(\"Downloaded file, saving to:\",save_location)\n","\n","def load_data(save_location):\n","    \"\"\"\n","    Load data from Textfile\n","    \"\"\"\n","    file = open(save_location,\"r\")\n","    data = file.read()\n","    return data\n","\n","def avg_char_per_title(data):\n","    \"\"\"\n","    Calculate the average number of chars in a title for the sequence length\n","    \"\"\"\n","    lines = data.split(\"\\n\")\n","    line_lengths = np.zeros(len(lines))\n","    for i,line in enumerate(lines):\n","        line_lengths[i] = len(line)\n","    return np.average(line_lengths)\n","        \n","\n","def save_object(obj, filename):\n","    \"\"\"\n","    Save an object - used to save models\n","    \"\"\"\n","    with open(filename, 'wb') as output:\n","        pickle.dump(obj, output, -1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ul28byP6P1TD"},"source":["# Change the URL to whatever text you want to train with\n","url = \"https://gist.githubusercontent.com/AngusTheMack/defadcbc503e2d625720661e9893ff0a/raw/bb978a5ef025ff104009ab8139da4a0b7367992f/Titles.txt\"\n","\n","# Save Location will be used to load the data in\n","save_location = \"Titles.txt\" # either the name of the file downloaded with the URL above, or the location of your own file to load in"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ISFZ_TFqV0Gi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638265971557,"user_tz":-300,"elapsed":400,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"c1bdec09-a6bd-432a-fff1-d28f2ea093c7"},"source":["# Downloads the data, and loads it in\n","download_data(url,save_location)\n","data = load_data(save_location)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Beginning file download...\n","Downloaded file, saving to: Titles.txt\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6fMA9EedQt96","executionInfo":{"status":"ok","timestamp":1638265980016,"user_tz":-300,"elapsed":410,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"00871eb6-c6f2-457b-b4b7-73e9c6ce09e4"},"source":["# Print first 100 characters of the data\n","print(data[:100])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Scikit-learn: Machine learning in Python\n","Pattern recognition and machine learning\n","Gaussian processes\n"]}]},{"cell_type":"code","metadata":{"id":"bD2yKRPGQwCR"},"source":["def clean_text(data):\n","    \"\"\"\n","    Removes non essential characters in corpus of text\n","    \"\"\"\n","    data = \"\".join(v for v in data if v not in string.punctuation).lower()\n","    data = data.encode(\"utf8\").decode(\"ascii\",'ignore')\n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EzoUZYmgQ1wy","executionInfo":{"status":"ok","timestamp":1638266012829,"user_tz":-300,"elapsed":1386,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"7a87e4d9-9a83-47ed-80ea-4cd3d749c30e"},"source":["# You don't need to clean, but it can make things simpler\n","cleaned = clean_text(data)\n","print(cleaned[:100])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["scikitlearn machine learning in python\n","pattern recognition and machine learning\n","gaussian processes i\n"]}]},{"cell_type":"code","metadata":{"id":"0UfXuWVLQ3jo"},"source":["def unique_chars(data):\n","    \"\"\"\n","    Get all unique Characters in the Dataset\n","    \"\"\"\n","    return list(set(data))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yc9Tx-MgQ6Oa","executionInfo":{"status":"ok","timestamp":1638266034859,"user_tz":-300,"elapsed":393,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"d320573a-29f7-4d27-e55c-ab1e2db7c7c8"},"source":["# Some info about the data\n","chars = unique_chars(cleaned)\n","data_size, input_size = len(cleaned), len(chars)\n","print(\"Data has %d characters, %d of them are unique\" % (data_size, input_size))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data has 64663 characters, 36 of them are unique\n"]}]},{"cell_type":"code","metadata":{"id":"uK-8uVaMQ9Oi"},"source":["def tokenize_chars(chars):\n","    \"\"\"\n","    Create dictionaries to make it easy to convert from tokens to chars\n","    \"\"\"\n","    char_to_idx = {ch:i for i,ch in enumerate(chars)}\n","    idx_to_char = {i:ch for i,ch in enumerate(chars)}\n","    return char_to_idx, idx_to_char"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0jxY6ohkQ_hN","executionInfo":{"status":"ok","timestamp":1638266055320,"user_tz":-300,"elapsed":805,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"dbb6edf1-e452-441c-b9d2-3090722afa00"},"source":["# Create dictionaries, and display example using 11 chars\n","char_to_idx, idx_to_char = tokenize_chars(chars)\n","first_title = cleaned[:11]\n","print(\"{0:<2}|{1:<2}\".format('Character', 'Index'))\n","print(\"________________\")\n","for i in range(len(first_title)):\n","    char_index = char_to_idx[first_title[i]]\n","    print(\"{0:<9}|{a:d}\".format(idx_to_char[char_index], a=char_to_idx[first_title[i]]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Character|Index\n","________________\n","s        |25\n","c        |5\n","i        |34\n","k        |30\n","i        |34\n","t        |12\n","l        |23\n","e        |1\n","a        |17\n","r        |6\n","n        |27\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"2aK_72r9RCH5","executionInfo":{"status":"ok","timestamp":1638266113868,"user_tz":-300,"elapsed":409,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"d4d5d474-f139-4b64-883b-96859ae4dffa"},"source":["# Chops the stream of titles into an array of titles based on new line characters\n","titles = cleaned.split(\"\\n\")\n","titles[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'scikitlearn machine learning in python'"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"csdoHFj4RQto"},"source":["unknown_token = \"UNKNOWN_TOKEN\"\n","title_start_token = \"SENTENCE_START\"\n","title_end_token = \"SENTENCE_END\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MtXrMmO5RScv"},"source":["# Add the start and end token to the title\n","titles = [\"%s %s %s\" % (title_start_token, x, title_end_token) for x in titles]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eq46afVdRT7n","executionInfo":{"status":"ok","timestamp":1638266159749,"user_tz":-300,"elapsed":1003,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"d75d7b1c-400a-409c-a412-421fa375c6e0"},"source":["# Ensure that nltk has the punkt package\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"XSEMCbN1RbxG"},"source":["tokenized_titles = [nltk.word_tokenize(t) for t in titles]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MgnouiEARd6I","executionInfo":{"status":"ok","timestamp":1638266178233,"user_tz":-300,"elapsed":378,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"3687a71b-0dd8-43e2-d099-9b1f2f0047f3"},"source":["word_freq = nltk.FreqDist(itertools.chain(*tokenized_titles))\n","print(\"Found %d unique words tokens.\" % len(word_freq.items()))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1841 unique words tokens.\n"]}]},{"cell_type":"code","metadata":{"id":"YvdX1Mu4RgbI"},"source":["vocabulary_size=2000#len(word_freq.items())\n","vocab = word_freq.most_common(vocabulary_size-1)\n","index_to_word = [x[0] for x in vocab]\n","index_to_word.append(unknown_token)\n","word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osNsYCZzRiA8","executionInfo":{"status":"ok","timestamp":1638266193420,"user_tz":-300,"elapsed":592,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"7b5cafb5-6de4-4411-8cef-73e3d5769e22"},"source":["print(\"Using vocabulary size %d.\" % vocabulary_size)\n","print(\"The least frequent word in our vocabulary is '%s' and appeared %d times.\" % (vocab[-1][0], vocab[-1][1]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using vocabulary size 2000.\n","The least frequent word in our vocabulary is 'ethical' and appeared 1 times.\n"]}]},{"cell_type":"code","metadata":{"id":"ypqJ0MtFRkF2"},"source":["# Replace all words not in our vocabulary with the unknown token\n","for i, sent in enumerate(tokenized_titles):\n","    tokenized_titles[i] = [w if w in word_to_index else unknown_token for w in sent]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QSauxwhRRmKQ","executionInfo":{"status":"ok","timestamp":1638266210017,"user_tz":-300,"elapsed":478,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"5ed679fa-fd15-457a-f3b1-b15789fbab02"},"source":["print(\"\\nExample sentence: '%s'\" % titles[0])\n","print(\"\\nExample sentence after Pre-processing: '%s'\" % tokenized_titles[0])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Example sentence: 'SENTENCE_START scikitlearn machine learning in python SENTENCE_END'\n","\n","Example sentence after Pre-processing: '['SENTENCE_START', 'scikitlearn', 'machine', 'learning', 'in', 'python', 'SENTENCE_END']'\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WHWYdCNwRoK0","executionInfo":{"status":"ok","timestamp":1638266218857,"user_tz":-300,"elapsed":503,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"c7d8ee92-f5d3-43d1-c965-16c0611a1fff"},"source":["# Create the training data\n","X_train = np.asarray([[word_to_index[w] for w in sent[:-1]] for sent in tokenized_titles])\n","y_train = np.asarray([[word_to_index[w] for w in sent[1:]] for sent in tokenized_titles])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gQ0AZ8RSRqKQ","executionInfo":{"status":"ok","timestamp":1638266225807,"user_tz":-300,"elapsed":378,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"cf7c2020-d633-48a1-89fc-801374658791"},"source":["# Print training data example\n","x_example, y_example = X_train[17], y_train[17]\n","print(\"x:\\n%s\\n%s\" % (\" \".join([index_to_word[x] for x in x_example]), x_example))\n","print(\"\\ny:\\n%s\\n%s\" % (\" \".join([index_to_word[x] for x in y_example]), y_example))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x:\n","SENTENCE_START supervised machine learning a review of classification techniques\n","[0, 66, 3, 2, 7, 49, 6, 16, 18]\n","\n","y:\n","supervised machine learning a review of classification techniques SENTENCE_END\n","[66, 3, 2, 7, 49, 6, 16, 18, 1]\n"]}]},{"cell_type":"code","metadata":{"id":"LinIJJLvRsBu"},"source":["def softmax(x):\n","    xt = np.exp(x - np.max(x))\n","    return xt / np.sum(xt)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OUJhsvnDRt9C"},"source":["class RNNNumpy:\n","    \n","    def __init__(self, word_dim, hidden_dim=100, bptt_truncate=4):\n","        # Assign instance variables\n","        self.word_dim = word_dim\n","        self.hidden_dim = hidden_dim\n","        self.bptt_truncate = bptt_truncate\n","        # Randomly initialize the network parameters\n","        self.U = np.random.uniform(-np.sqrt(1./word_dim), np.sqrt(1./word_dim), (hidden_dim, word_dim))\n","        self.V = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (word_dim, hidden_dim))\n","        self.W = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (hidden_dim, hidden_dim))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ta8tpNLQRwFq"},"source":["def forward_propagation(self, x):\n","    # The total number of time steps\n","    T = len(x)\n","    # During forward propagation we save all hidden states in s because need them later.\n","    # We add one additional element for the initial hidden, which we set to 0\n","    s = np.zeros((T + 1, self.hidden_dim))\n","    s[-1] = np.zeros(self.hidden_dim)\n","    # The outputs at each time step. Again, we save them for later.\n","    o = np.zeros((T, self.word_dim))\n","    # For each time step...\n","    for t in np.arange(T):\n","        # Note that we are indxing U by x[t]. This is the same as multiplying U with a one-hot vector.\n","        s[t] = np.tanh(self.U[:,x[t]] + self.W.dot(s[t-1]))\n","        o[t] = softmax(self.V.dot(s[t]))\n","    return [o, s]\n","\n","RNNNumpy.forward_propagation = forward_propagation\n","\n","def predict(self, x):\n","    # Perform forward propagation and return index of the highest score\n","    o, s = self.forward_propagation(x)\n","    return np.argmax(o, axis=1)\n","\n","RNNNumpy.predict = predict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cxg4SZ8yRyqB","executionInfo":{"status":"ok","timestamp":1638266262449,"user_tz":-300,"elapsed":386,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"180211d9-60c5-4847-d17d-3d3fb8e8f68a"},"source":["np.random.seed(10)\n","model = RNNNumpy(vocabulary_size)\n","o, s = model.forward_propagation(X_train[10])\n","print(o.shape)\n","print(o)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(5, 2000)\n","[[0.00050094 0.00049585 0.00050577 ... 0.00050363 0.00049082 0.00049915]\n"," [0.00050011 0.00050381 0.00050253 ... 0.00050514 0.00050839 0.0005072 ]\n"," [0.00050025 0.00049864 0.00049696 ... 0.00049498 0.00049688 0.00050403]\n"," [0.00050167 0.00050213 0.00049959 ... 0.00049484 0.00050239 0.00050337]\n"," [0.00050468 0.00049741 0.00050422 ... 0.00050882 0.00050223 0.00051026]]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3lszb6VAR0_m","executionInfo":{"status":"ok","timestamp":1638266268822,"user_tz":-300,"elapsed":396,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"813f62a1-8939-4063-be11-e352e85e423b"},"source":["predictions = model.predict(X_train[10])\n","print(predictions.shape)\n","print(predictions)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(5,)\n","[1755  202    3 1314 1300]\n"]}]},{"cell_type":"code","metadata":{"id":"7C-lZB3pR2i5"},"source":["def calculate_total_loss(self, x, y):\n","    L = 0\n","    # For each sentence...\n","    for i in np.arange(len(y)):\n","        o, s = self.forward_propagation(x[i])\n","        # We only care about our prediction of the \"correct\" words\n","        correct_word_predictions = o[np.arange(len(y[i])), y[i]]\n","        # Add to the loss based on how off we were\n","        L += -1 * np.sum(np.log(correct_word_predictions))\n","    return L\n","\n","def calculate_loss(self, x, y):\n","    # Divide the total loss by the number of training examples\n","    N = np.sum((len(y_i) for y_i in y))\n","    return self.calculate_total_loss(x,y)/N\n","\n","RNNNumpy.calculate_total_loss = calculate_total_loss\n","RNNNumpy.calculate_loss = calculate_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6wGARNiSR5Wy","executionInfo":{"status":"ok","timestamp":1638266290121,"user_tz":-300,"elapsed":2277,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"24c2c5ad-ad42-4ffc-e193-0e9d3b5ab264"},"source":["# Limit to 1000 examples to save time\n","print(\"Expected Loss for random predictions: %f\" % np.log(vocabulary_size))\n","print(\"Actual loss: %f\" % model.calculate_loss(X_train[:1000], y_train[:1000]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Expected Loss for random predictions: 7.600902\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n","  \n"]},{"output_type":"stream","name":"stdout","text":["Actual loss: 7.601436\n"]}]},{"cell_type":"code","metadata":{"id":"KWUEjsmVR7R1"},"source":["def bptt(self, x, y):\n","    T = len(y)\n","    # Perform forward propagation\n","    o, s = self.forward_propagation(x)\n","    # We accumulate the gradients in these variables\n","    dLdU = np.zeros(self.U.shape)\n","    dLdV = np.zeros(self.V.shape)\n","    dLdW = np.zeros(self.W.shape)\n","    delta_o = o\n","    delta_o[np.arange(len(y)), y] -= 1.\n","    # For each output backwards...\n","    for t in np.arange(T)[::-1]:\n","        dLdV += np.outer(delta_o[t], s[t].T)\n","        # Initial delta calculation\n","        delta_t = self.V.T.dot(delta_o[t]) * (1 - (s[t] ** 2))\n","        # Backpropagation through time (for at most self.bptt_truncate steps)\n","        for bptt_step in np.arange(max(0, t-self.bptt_truncate), t+1)[::-1]:\n","            # print \"Backpropagation step t=%d bptt step=%d \" % (t, bptt_step)\n","            dLdW += np.outer(delta_t, s[bptt_step-1])              \n","            dLdU[:,x[bptt_step]] += delta_t\n","            # Update delta for next step\n","            delta_t = self.W.T.dot(delta_t) * (1 - s[bptt_step-1] ** 2)\n","    return [dLdU, dLdV, dLdW]\n","\n","RNNNumpy.bptt = bptt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WMNO98S3SDkQ","executionInfo":{"status":"ok","timestamp":1638266339389,"user_tz":-300,"elapsed":422,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"0ce1a753-9de4-455e-91c3-e03d95ef1dd3"},"source":["def gradient_check(self, x, y, h=0.001, error_threshold=0.01):\n","    # Calculate the gradients using backpropagation. We want to checker if these are correct.\n","    bptt_gradients = model.bptt(x, y)\n","    # List of all parameters we want to check.\n","    model_parameters = ['U', 'V', 'W']\n","    # Gradient check for each parameter\n","    for pidx, pname in enumerate(model_parameters):\n","        # Get the actual parameter value from the mode, e.g. model.W\n","        parameter = operator.attrgetter(pname)(self)\n","        print(\"Performing gradient check for parameter %s with size %d.\" % (pname, np.prod(parameter.shape)))\n","        # Iterate over each element of the parameter matrix, e.g. (0,0), (0,1), ...\n","        it = np.nditer(parameter, flags=['multi_index'], op_flags=['readwrite'])\n","        while not it.finished:\n","            ix = it.multi_index\n","            # Save the original value so we can reset it later\n","            original_value = parameter[ix]\n","            # Estimate the gradient using (f(x+h) - f(x-h))/(2*h)\n","            parameter[ix] = original_value + h\n","            gradplus = model.calculate_total_loss([x],[y])\n","            parameter[ix] = original_value - h\n","            gradminus = model.calculate_total_loss([x],[y])\n","            estimated_gradient = (gradplus - gradminus)/(2*h)\n","            # Reset parameter to original value\n","            parameter[ix] = original_value\n","            # The gradient for this parameter calculated using backpropagation\n","            backprop_gradient = bptt_gradients[pidx][ix]\n","            # calculate The relative error: (|x - y|/(|x| + |y|))\n","            relative_error = np.abs(backprop_gradient - estimated_gradient)/(np.abs(backprop_gradient) + np.abs(estimated_gradient))\n","            # If the error is to large fail the gradient check\n","            if relative_error > error_threshold:\n","                print(\"Gradient Check ERROR: parameter=%s ix=%s\" % (pname, ix))\n","                print(\"+h Loss: %f\" % gradplus)\n","                print(\"-h Loss: %f\" % gradminus)\n","                print(\"Estimated_gradient: %f\" % estimated_gradient)\n","                print(\"Backpropagation gradient: %f\" % backprop_gradient)\n","                print(\"Relative Error: %f\" % relative_error)\n","                return \n","            it.iternext()\n","        print(\"Gradient check for parameter %s passed.\" % (pname))\n","\n","RNNNumpy.gradient_check = gradient_check\n","\n","# To avoid performing millions of expensive calculations we use a smaller vocabulary size for checking.\n","grad_check_vocab_size = 100\n","np.random.seed(10)\n","word_model = RNNNumpy(grad_check_vocab_size, 10, bptt_truncate=1000)\n","word_model.gradient_check([0,1,2,3], [1,2,3,4])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing gradient check for parameter U with size 1000.\n","Gradient Check ERROR: parameter=U ix=(0, 0)\n","+h Loss: 30.432536\n","-h Loss: 30.432536\n","Estimated_gradient: 0.000000\n","Backpropagation gradient: -0.177072\n","Relative Error: 1.000000\n"]}]},{"cell_type":"code","metadata":{"id":"IUAIOTWqSHwk"},"source":["# Performs one step of SGD.\n","def numpy_sdg_step(self, x, y, learning_rate):\n","    # Calculate the gradients\n","    dLdU, dLdV, dLdW = self.bptt(x, y)\n","    # Change parameters according to gradients and learning rate\n","    self.U -= learning_rate * dLdU\n","    self.V -= learning_rate * dLdV\n","    self.W -= learning_rate * dLdW\n","\n","RNNNumpy.sgd_step = numpy_sdg_step"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3KPea4bqSK9K"},"source":["# Outer SGD Loop\n","# - model: The RNN model instance\n","# - X_train: The training data set\n","# - y_train: The training data labels\n","# - learning_rate: Initial learning rate for SGD\n","# - nepoch: Number of times to iterate through the complete dataset\n","# - evaluate_loss_after: Evaluate the loss after this many epochs\n","def train_with_sgd(model, X_train, y_train, learning_rate=0.005, nepoch=100, evaluate_loss_after=5):\n","    # We keep track of the losses so we can plot them later\n","    losses = []\n","    num_examples_seen = 0\n","    for epoch in range(nepoch):\n","        # Optionally evaluate the loss\n","        if (epoch % evaluate_loss_after == 0):\n","            loss = model.calculate_loss(X_train, y_train)\n","            losses.append((num_examples_seen, loss))\n","            time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n","            print(\"%s: Loss after num_examples_seen=%d epoch=%d: %f\" % (time, num_examples_seen, epoch, loss))\n","            # Adjust the learning rate if loss increases\n","            if (len(losses) > 1 and losses[-1][1] > losses[-2][1]):\n","                learning_rate = learning_rate * 0.5  \n","                print(\"Setting learning rate to %f\" % learning_rate)\n","            sys.stdout.flush()\n","        # For each training example...\n","        for i in range(len(y_train)):\n","            # One SGD step\n","            model.sgd_step(X_train[i], y_train[i], learning_rate)\n","            num_examples_seen += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mN1OOuajSOhl","executionInfo":{"status":"ok","timestamp":1638266380774,"user_tz":-300,"elapsed":4867,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"e0155274-04b2-4266-97cd-a85c4b6082bb"},"source":["np.random.seed(10)\n","word_model = RNNNumpy(vocabulary_size)\n","%timeit model.sgd_step(X_train[10], y_train[10], 0.005)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["100 loops, best of 5: 7.29 ms per loop\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nodCqx2DSQwP","executionInfo":{"status":"ok","timestamp":1638267875209,"user_tz":-300,"elapsed":1485169,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"cd59bbf6-22af-445c-ef00-605b0f3b591c"},"source":["np.random.seed(10)\n","model = RNNNumpy(vocabulary_size)\n","losses = train_with_sgd(model, X_train[:1000], y_train[:1000], nepoch=100, evaluate_loss_after=1)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n","  \n"]},{"output_type":"stream","name":"stdout","text":["2021-11-30 09:59:51: Loss after num_examples_seen=0 epoch=0: 7.601436\n","2021-11-30 10:00:06: Loss after num_examples_seen=950 epoch=1: 5.101324\n","2021-11-30 10:00:21: Loss after num_examples_seen=1900 epoch=2: 4.884683\n","2021-11-30 10:00:36: Loss after num_examples_seen=2850 epoch=3: 4.782096\n","2021-11-30 10:00:51: Loss after num_examples_seen=3800 epoch=4: 4.696497\n","2021-11-30 10:01:06: Loss after num_examples_seen=4750 epoch=5: 4.617869\n","2021-11-30 10:01:20: Loss after num_examples_seen=5700 epoch=6: 4.550876\n","2021-11-30 10:01:35: Loss after num_examples_seen=6650 epoch=7: 4.489871\n","2021-11-30 10:01:50: Loss after num_examples_seen=7600 epoch=8: 4.432672\n","2021-11-30 10:02:05: Loss after num_examples_seen=8550 epoch=9: 4.378976\n","2021-11-30 10:02:20: Loss after num_examples_seen=9500 epoch=10: 4.327513\n","2021-11-30 10:02:34: Loss after num_examples_seen=10450 epoch=11: 4.277692\n","2021-11-30 10:02:49: Loss after num_examples_seen=11400 epoch=12: 4.230520\n","2021-11-30 10:03:04: Loss after num_examples_seen=12350 epoch=13: 4.188986\n","2021-11-30 10:03:19: Loss after num_examples_seen=13300 epoch=14: 4.152355\n","2021-11-30 10:03:34: Loss after num_examples_seen=14250 epoch=15: 4.104458\n","2021-11-30 10:03:48: Loss after num_examples_seen=15200 epoch=16: 4.068339\n","2021-11-30 10:04:03: Loss after num_examples_seen=16150 epoch=17: 4.036206\n","2021-11-30 10:04:18: Loss after num_examples_seen=17100 epoch=18: 3.980106\n","2021-11-30 10:04:33: Loss after num_examples_seen=18050 epoch=19: 3.948859\n","2021-11-30 10:04:48: Loss after num_examples_seen=19000 epoch=20: 3.922072\n","2021-11-30 10:05:02: Loss after num_examples_seen=19950 epoch=21: 3.897618\n","2021-11-30 10:05:17: Loss after num_examples_seen=20900 epoch=22: 3.870222\n","2021-11-30 10:05:32: Loss after num_examples_seen=21850 epoch=23: 3.843700\n","2021-11-30 10:05:47: Loss after num_examples_seen=22800 epoch=24: 3.830593\n","2021-11-30 10:06:02: Loss after num_examples_seen=23750 epoch=25: 3.801406\n","2021-11-30 10:06:16: Loss after num_examples_seen=24700 epoch=26: 3.778610\n","2021-11-30 10:06:31: Loss after num_examples_seen=25650 epoch=27: 3.773279\n","2021-11-30 10:06:46: Loss after num_examples_seen=26600 epoch=28: 3.785431\n","Setting learning rate to 0.002500\n","2021-11-30 10:07:01: Loss after num_examples_seen=27550 epoch=29: 3.676958\n","2021-11-30 10:07:15: Loss after num_examples_seen=28500 epoch=30: 3.658140\n","2021-11-30 10:07:30: Loss after num_examples_seen=29450 epoch=31: 3.640486\n","2021-11-30 10:07:45: Loss after num_examples_seen=30400 epoch=32: 3.629959\n","2021-11-30 10:08:00: Loss after num_examples_seen=31350 epoch=33: 3.623627\n","2021-11-30 10:08:14: Loss after num_examples_seen=32300 epoch=34: 3.621406\n","2021-11-30 10:08:29: Loss after num_examples_seen=33250 epoch=35: 3.618272\n","2021-11-30 10:08:44: Loss after num_examples_seen=34200 epoch=36: 3.617259\n","2021-11-30 10:08:59: Loss after num_examples_seen=35150 epoch=37: 3.606605\n","2021-11-30 10:09:13: Loss after num_examples_seen=36100 epoch=38: 3.611525\n","Setting learning rate to 0.001250\n","2021-11-30 10:09:28: Loss after num_examples_seen=37050 epoch=39: 3.514323\n","2021-11-30 10:09:43: Loss after num_examples_seen=38000 epoch=40: 3.505757\n","2021-11-30 10:09:58: Loss after num_examples_seen=38950 epoch=41: 3.498466\n","2021-11-30 10:10:13: Loss after num_examples_seen=39900 epoch=42: 3.492732\n","2021-11-30 10:10:28: Loss after num_examples_seen=40850 epoch=43: 3.490767\n","2021-11-30 10:10:42: Loss after num_examples_seen=41800 epoch=44: 3.487777\n","2021-11-30 10:10:57: Loss after num_examples_seen=42750 epoch=45: 3.484647\n","2021-11-30 10:11:12: Loss after num_examples_seen=43700 epoch=46: 3.481012\n","2021-11-30 10:11:27: Loss after num_examples_seen=44650 epoch=47: 3.476875\n","2021-11-30 10:11:41: Loss after num_examples_seen=45600 epoch=48: 3.474460\n","2021-11-30 10:11:56: Loss after num_examples_seen=46550 epoch=49: 3.471919\n","2021-11-30 10:12:11: Loss after num_examples_seen=47500 epoch=50: 3.471693\n","2021-11-30 10:12:26: Loss after num_examples_seen=48450 epoch=51: 3.469422\n","2021-11-30 10:12:40: Loss after num_examples_seen=49400 epoch=52: 3.466541\n","2021-11-30 10:12:55: Loss after num_examples_seen=50350 epoch=53: 3.463631\n","2021-11-30 10:13:10: Loss after num_examples_seen=51300 epoch=54: 3.459431\n","2021-11-30 10:13:25: Loss after num_examples_seen=52250 epoch=55: 3.459166\n","2021-11-30 10:13:39: Loss after num_examples_seen=53200 epoch=56: 3.461517\n","Setting learning rate to 0.000625\n","2021-11-30 10:13:54: Loss after num_examples_seen=54150 epoch=57: 3.426817\n","2021-11-30 10:14:09: Loss after num_examples_seen=55100 epoch=58: 3.419599\n","2021-11-30 10:14:24: Loss after num_examples_seen=56050 epoch=59: 3.419486\n","2021-11-30 10:14:39: Loss after num_examples_seen=57000 epoch=60: 3.419226\n","2021-11-30 10:14:54: Loss after num_examples_seen=57950 epoch=61: 3.422268\n","Setting learning rate to 0.000313\n","2021-11-30 10:15:09: Loss after num_examples_seen=58900 epoch=62: 3.359926\n","2021-11-30 10:15:24: Loss after num_examples_seen=59850 epoch=63: 3.356051\n","2021-11-30 10:15:39: Loss after num_examples_seen=60800 epoch=64: 3.351818\n","2021-11-30 10:15:54: Loss after num_examples_seen=61750 epoch=65: 3.349039\n","2021-11-30 10:16:08: Loss after num_examples_seen=62700 epoch=66: 3.347359\n","2021-11-30 10:16:23: Loss after num_examples_seen=63650 epoch=67: 3.346000\n","2021-11-30 10:16:38: Loss after num_examples_seen=64600 epoch=68: 3.344480\n","2021-11-30 10:16:53: Loss after num_examples_seen=65550 epoch=69: 3.342779\n","2021-11-30 10:17:08: Loss after num_examples_seen=66500 epoch=70: 3.340907\n","2021-11-30 10:17:23: Loss after num_examples_seen=67450 epoch=71: 3.338904\n","2021-11-30 10:17:38: Loss after num_examples_seen=68400 epoch=72: 3.336873\n","2021-11-30 10:17:53: Loss after num_examples_seen=69350 epoch=73: 3.334953\n","2021-11-30 10:18:08: Loss after num_examples_seen=70300 epoch=74: 3.333219\n","2021-11-30 10:18:23: Loss after num_examples_seen=71250 epoch=75: 3.331656\n","2021-11-30 10:18:38: Loss after num_examples_seen=72200 epoch=76: 3.330203\n","2021-11-30 10:18:53: Loss after num_examples_seen=73150 epoch=77: 3.328817\n","2021-11-30 10:19:08: Loss after num_examples_seen=74100 epoch=78: 3.327497\n","2021-11-30 10:19:23: Loss after num_examples_seen=75050 epoch=79: 3.326268\n","2021-11-30 10:19:38: Loss after num_examples_seen=76000 epoch=80: 3.325132\n","2021-11-30 10:19:53: Loss after num_examples_seen=76950 epoch=81: 3.324070\n","2021-11-30 10:20:07: Loss after num_examples_seen=77900 epoch=82: 3.323056\n","2021-11-30 10:20:22: Loss after num_examples_seen=78850 epoch=83: 3.322084\n","2021-11-30 10:20:37: Loss after num_examples_seen=79800 epoch=84: 3.321156\n","2021-11-30 10:20:52: Loss after num_examples_seen=80750 epoch=85: 3.320263\n","2021-11-30 10:21:07: Loss after num_examples_seen=81700 epoch=86: 3.319397\n","2021-11-30 10:21:22: Loss after num_examples_seen=82650 epoch=87: 3.318558\n","2021-11-30 10:21:37: Loss after num_examples_seen=83600 epoch=88: 3.317747\n","2021-11-30 10:21:52: Loss after num_examples_seen=84550 epoch=89: 3.316949\n","2021-11-30 10:22:07: Loss after num_examples_seen=85500 epoch=90: 3.316126\n","2021-11-30 10:22:22: Loss after num_examples_seen=86450 epoch=91: 3.315257\n","2021-11-30 10:22:36: Loss after num_examples_seen=87400 epoch=92: 3.314345\n","2021-11-30 10:22:51: Loss after num_examples_seen=88350 epoch=93: 3.313434\n","2021-11-30 10:23:06: Loss after num_examples_seen=89300 epoch=94: 3.312580\n","2021-11-30 10:23:21: Loss after num_examples_seen=90250 epoch=95: 3.311830\n","2021-11-30 10:23:36: Loss after num_examples_seen=91200 epoch=96: 3.311220\n","2021-11-30 10:23:51: Loss after num_examples_seen=92150 epoch=97: 3.310755\n","2021-11-30 10:24:06: Loss after num_examples_seen=93100 epoch=98: 3.310417\n","2021-11-30 10:24:21: Loss after num_examples_seen=94050 epoch=99: 3.310179\n"]}]},{"cell_type":"code","metadata":{"id":"NS9xtp-ygHcy"},"source":["sentence_start_token = 'sentence_start'\n","sentence_end_token = 'sentence_end'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dglz99JcSUPL","executionInfo":{"status":"ok","timestamp":1638271209846,"user_tz":-300,"elapsed":374,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"38820ca7-d1c9-49b1-9570-d7c2397a4eac"},"source":["def generate_sentence(model):\n","    # We start the sentence with the start token\n","    new_sentence = [word_to_index[title_start_token]]\n","    # Repeat until we get an end token\n","    while not new_sentence[-1] == word_to_index[title_end_token]:\n","        next_word_probs = model.forward_propagation(new_sentence)\n","        #print(next_word_probs[0][-1])\n","        #print(max(next_word_probs[0][-1]))\n","        sampled_word = word_to_index[unknown_token]\n","        # We don't want to sample unknown words\n","        while sampled_word == word_to_index[unknown_token]:\n","            samples = np.random.multinomial(1, next_word_probs[0][-1])\n","            sampled_word = np.argmax(samples)\n","        new_sentence.append(sampled_word)\n","    sentence_str = [index_to_word[x] for x in new_sentence[1:-1]]\n","    return sentence_str\n","\n","num_sentences = 15\n","senten_min_length = 5\n","\n","for i in range(num_sentences):\n","    sent = []\n","    # We want long sentences, not sentences with one or two words\n","    while len(sent) < senten_min_length:\n","        sent = generate_sentence(model)\n","    print(\" \".join(sent).title())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Two Berlin A Machine Learning To Frontier Retrieval\n","Machine Learning Of Medical Microscopy Analytics In Functions\n","A Machinelearning Approach To Speech Classifying Expression On Algorithms By Identification\n","Towards Classification Of Data Calls In A Induction Learning The Image Output\n","A Framework Studies For Machinelearning Class And Machine Learning Algorithms\n","Automated Dependency Of Imbalanced Modeling Towards Up Using Machine Learning\n","Predicting Mutants Matlablike Learn Human Parallel And The Classificationa Profiling Machine\n","Global Extreme Learning Machine For The The\n","Multimodal Pharmaceutical 00 Analysis Through Routine Android For Mri Machine Machine Techniques\n","Statistical Zoo Methods And Machine Learning\n","Adaptive Size Improve Matrix Modeling Using Machine Learning Using Gene Synthesis\n","Machine Learning Of Applied Rules Recent In Relevance Ecosystem Optimal Control Networks Challenges\n","On Machine Learning To Digital Pathology Assembly In Power At Programming\n","Machine Learning Bias Optimize Models Heterogeneous And Prediction Research Algorithms And Computer State\n","A Supervised Machine Learning Regression To Automatic Function Of Cancer Researchcommentary\n"]}]},{"cell_type":"markdown","metadata":{"id":"RCq7SDJFkA43"},"source":["## Sentences generated by the machine"]},{"cell_type":"code","metadata":{"id":"UW7dI9b7Yaq5"},"source":["# Sentence_Start A Machinelearning Approach For Automated Prediction\n","# Sentence_Start Image Machine Learning In Forwardlooking The Practical Output\n","# Sentence_Start On Multiple Comparison And Machine Learning Classifiers For Information Need State Advice Methods\n","# Sentence_Start A Comparison Of Supervised Machine Inhibitors In Program Emotion\n","# Sentence_Start Cognitive Page Qlearning Using 101 Microbial In Machine Learning\n","# Sentence_Start A Machine Learning Intensitybased For Inductive And Text\n","# Sentence_Start Meta Stealthy Construction Recognizing Information Using Using Machine Learning Approach\n","# Sentence_Start Psychosis Shape New Classification With Program Machine Learning\n","# Sentence_Start Drift Machine Learning Framework To Coreference Recognition\n","# Sentence_Start Using Machine Learning To Financial Efficient Prediction In Domain Iirecent Output\n","# Sentence_Start A Machinelearning Approach For Predicting Pixel\n","# Sentence_Start Webwatcher Machine Learning In Interpretable\n","# Sentence_Start Introduction To A Machine Learning Of Decision Supply\n","# Sentence_Start Health Annotator Annotation And Machine Learning Based Symbolic Authorship Datasets\n","# Sentence_Start Machine Learning System To Fully Prediction In Mobile Behavior Analysis\n","\n","# Next execution sentence generated\n","\n","# Two Berlin A Machine Learning To Frontier Retrieval\n","# Machine Learning Of Medical Microscopy Analytics In Functions\n","# A Machinelearning Approach To Speech Classifying Expression On Algorithms By Identification\n","# Towards Classification Of Data Calls In A Induction Learning The Image Output\n","# A Framework Studies For Machinelearning Class And Machine Learning Algorithms\n","# Automated Dependency Of Imbalanced Modeling Towards Up Using Machine Learning\n","# Predicting Mutants Matlablike Learn Human Parallel And The Classificationa Profiling Machine\n","# Global Extreme Learning Machine For The The\n","# Multimodal Pharmaceutical 00 Analysis Through Routine Android For Mri Machine Machine Techniques\n","# Statistical Zoo Methods And Machine Learning\n","# Adaptive Size Improve Matrix Modeling Using Machine Learning Using Gene Synthesis\n","# Machine Learning Of Applied Rules Recent In Relevance Ecosystem Optimal Control Networks Challenges\n","# On Machine Learning To Digital Pathology Assembly In Power At Programming\n","# Machine Learning Bias Optimize Models Heterogeneous And Prediction Research Algorithms And Compu"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cvjsrABwlHjk"},"source":["!cp '/content/Titles.txt' -d '/content/drive/MyDrive/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zcwTgC7ZxmLD","executionInfo":{"status":"ok","timestamp":1638276199810,"user_tz":-300,"elapsed":3799,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"203753e8-e4fc-4b51-c283-92db248b039a"},"source":["from keras.applications.inception_v3 import InceptionV3\n","\n","inception = InceptionV3(weights='imagenet', input_shape=(220, 220, 3), include_top=False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87916544/87910968 [==============================] - 1s 0us/step\n","87924736/87910968 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"code","metadata":{"id":"x-hHJGUq2vJC"},"source":["for layer in inception.layers:\n","  layer.trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AD0U2spa4iLS","executionInfo":{"status":"ok","timestamp":1638276450150,"user_tz":-300,"elapsed":800,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"6fc76d8c-9182-4daf-d2cf-01a458619c39"},"source":["inception.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"inception_v3\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 220, 220, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 109, 109, 32  864         ['input_1[0][0]']                \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 109, 109, 32  96         ['conv2d[0][0]']                 \n"," alization)                     )                                                                 \n","                                                                                                  \n"," activation (Activation)        (None, 109, 109, 32  0           ['batch_normalization[0][0]']    \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 107, 107, 32  9216        ['activation[0][0]']             \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 107, 107, 32  96         ['conv2d_1[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," activation_1 (Activation)      (None, 107, 107, 32  0           ['batch_normalization_1[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 107, 107, 64  18432       ['activation_1[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 107, 107, 64  192        ['conv2d_2[0][0]']               \n"," rmalization)                   )                                                                 \n","                                                                                                  \n"," activation_2 (Activation)      (None, 107, 107, 64  0           ['batch_normalization_2[0][0]']  \n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d (MaxPooling2D)   (None, 53, 53, 64)   0           ['activation_2[0][0]']           \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 53, 53, 80)   5120        ['max_pooling2d[0][0]']          \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 53, 53, 80)  240         ['conv2d_3[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_3 (Activation)      (None, 53, 53, 80)   0           ['batch_normalization_3[0][0]']  \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 51, 51, 192)  138240      ['activation_3[0][0]']           \n","                                                                                                  \n"," batch_normalization_4 (BatchNo  (None, 51, 51, 192)  576        ['conv2d_4[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_4 (Activation)      (None, 51, 51, 192)  0           ['batch_normalization_4[0][0]']  \n","                                                                                                  \n"," max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0          ['activation_4[0][0]']           \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n","                                                                                                  \n"," batch_normalization_8 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_8[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_8 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_8[0][0]']  \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 25, 25, 48)   9216        ['max_pooling2d_1[0][0]']        \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 25, 25, 96)   55296       ['activation_8[0][0]']           \n","                                                                                                  \n"," batch_normalization_6 (BatchNo  (None, 25, 25, 48)  144         ['conv2d_6[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," batch_normalization_9 (BatchNo  (None, 25, 25, 96)  288         ['conv2d_9[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," activation_6 (Activation)      (None, 25, 25, 48)   0           ['batch_normalization_6[0][0]']  \n","                                                                                                  \n"," activation_9 (Activation)      (None, 25, 25, 96)   0           ['batch_normalization_9[0][0]']  \n","                                                                                                  \n"," average_pooling2d (AveragePool  (None, 25, 25, 192)  0          ['max_pooling2d_1[0][0]']        \n"," ing2D)                                                                                           \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 25, 25, 64)   76800       ['activation_6[0][0]']           \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_9[0][0]']           \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 25, 25, 32)   6144        ['average_pooling2d[0][0]']      \n","                                                                                                  \n"," batch_normalization_5 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_5[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," batch_normalization_7 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_7[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," batch_normalization_10 (BatchN  (None, 25, 25, 96)  288         ['conv2d_10[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_11 (BatchN  (None, 25, 25, 32)  96          ['conv2d_11[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_5 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_5[0][0]']  \n","                                                                                                  \n"," activation_7 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_7[0][0]']  \n","                                                                                                  \n"," activation_10 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_10[0][0]'] \n","                                                                                                  \n"," activation_11 (Activation)     (None, 25, 25, 32)   0           ['batch_normalization_11[0][0]'] \n","                                                                                                  \n"," mixed0 (Concatenate)           (None, 25, 25, 256)  0           ['activation_5[0][0]',           \n","                                                                  'activation_7[0][0]',           \n","                                                                  'activation_10[0][0]',          \n","                                                                  'activation_11[0][0]']          \n","                                                                                                  \n"," conv2d_15 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n","                                                                                                  \n"," batch_normalization_15 (BatchN  (None, 25, 25, 64)  192         ['conv2d_15[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_15 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_15[0][0]'] \n","                                                                                                  \n"," conv2d_13 (Conv2D)             (None, 25, 25, 48)   12288       ['mixed0[0][0]']                 \n","                                                                                                  \n"," conv2d_16 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_15[0][0]']          \n","                                                                                                  \n"," batch_normalization_13 (BatchN  (None, 25, 25, 48)  144         ['conv2d_13[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_16 (BatchN  (None, 25, 25, 96)  288         ['conv2d_16[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_13 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_13[0][0]'] \n","                                                                                                  \n"," activation_16 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_16[0][0]'] \n","                                                                                                  \n"," average_pooling2d_1 (AveragePo  (None, 25, 25, 256)  0          ['mixed0[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n","                                                                                                  \n"," conv2d_14 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_13[0][0]']          \n","                                                                                                  \n"," conv2d_17 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_16[0][0]']          \n","                                                                                                  \n"," conv2d_18 (Conv2D)             (None, 25, 25, 64)   16384       ['average_pooling2d_1[0][0]']    \n","                                                                                                  \n"," batch_normalization_12 (BatchN  (None, 25, 25, 64)  192         ['conv2d_12[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_14 (BatchN  (None, 25, 25, 64)  192         ['conv2d_14[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_17 (BatchN  (None, 25, 25, 96)  288         ['conv2d_17[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_18 (BatchN  (None, 25, 25, 64)  192         ['conv2d_18[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_12 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_12[0][0]'] \n","                                                                                                  \n"," activation_14 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_14[0][0]'] \n","                                                                                                  \n"," activation_17 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_17[0][0]'] \n","                                                                                                  \n"," activation_18 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_18[0][0]'] \n","                                                                                                  \n"," mixed1 (Concatenate)           (None, 25, 25, 288)  0           ['activation_12[0][0]',          \n","                                                                  'activation_14[0][0]',          \n","                                                                  'activation_17[0][0]',          \n","                                                                  'activation_18[0][0]']          \n","                                                                                                  \n"," conv2d_22 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n","                                                                                                  \n"," batch_normalization_22 (BatchN  (None, 25, 25, 64)  192         ['conv2d_22[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_22 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_22[0][0]'] \n","                                                                                                  \n"," conv2d_20 (Conv2D)             (None, 25, 25, 48)   13824       ['mixed1[0][0]']                 \n","                                                                                                  \n"," conv2d_23 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_22[0][0]']          \n","                                                                                                  \n"," batch_normalization_20 (BatchN  (None, 25, 25, 48)  144         ['conv2d_20[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_23 (BatchN  (None, 25, 25, 96)  288         ['conv2d_23[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_20 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_20[0][0]'] \n","                                                                                                  \n"," activation_23 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_23[0][0]'] \n","                                                                                                  \n"," average_pooling2d_2 (AveragePo  (None, 25, 25, 288)  0          ['mixed1[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_19 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n","                                                                                                  \n"," conv2d_21 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_20[0][0]']          \n","                                                                                                  \n"," conv2d_24 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_23[0][0]']          \n","                                                                                                  \n"," conv2d_25 (Conv2D)             (None, 25, 25, 64)   18432       ['average_pooling2d_2[0][0]']    \n","                                                                                                  \n"," batch_normalization_19 (BatchN  (None, 25, 25, 64)  192         ['conv2d_19[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_21 (BatchN  (None, 25, 25, 64)  192         ['conv2d_21[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_24 (BatchN  (None, 25, 25, 96)  288         ['conv2d_24[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_25 (BatchN  (None, 25, 25, 64)  192         ['conv2d_25[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_19 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_19[0][0]'] \n","                                                                                                  \n"," activation_21 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_21[0][0]'] \n","                                                                                                  \n"," activation_24 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_24[0][0]'] \n","                                                                                                  \n"," activation_25 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_25[0][0]'] \n","                                                                                                  \n"," mixed2 (Concatenate)           (None, 25, 25, 288)  0           ['activation_19[0][0]',          \n","                                                                  'activation_21[0][0]',          \n","                                                                  'activation_24[0][0]',          \n","                                                                  'activation_25[0][0]']          \n","                                                                                                  \n"," conv2d_27 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed2[0][0]']                 \n","                                                                                                  \n"," batch_normalization_27 (BatchN  (None, 25, 25, 64)  192         ['conv2d_27[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_27 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_27[0][0]'] \n","                                                                                                  \n"," conv2d_28 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_27[0][0]']          \n","                                                                                                  \n"," batch_normalization_28 (BatchN  (None, 25, 25, 96)  288         ['conv2d_28[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_28 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_28[0][0]'] \n","                                                                                                  \n"," conv2d_26 (Conv2D)             (None, 12, 12, 384)  995328      ['mixed2[0][0]']                 \n","                                                                                                  \n"," conv2d_29 (Conv2D)             (None, 12, 12, 96)   82944       ['activation_28[0][0]']          \n","                                                                                                  \n"," batch_normalization_26 (BatchN  (None, 12, 12, 384)  1152       ['conv2d_26[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_29 (BatchN  (None, 12, 12, 96)  288         ['conv2d_29[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_26 (Activation)     (None, 12, 12, 384)  0           ['batch_normalization_26[0][0]'] \n","                                                                                                  \n"," activation_29 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_29[0][0]'] \n","                                                                                                  \n"," max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0          ['mixed2[0][0]']                 \n","                                                                                                  \n"," mixed3 (Concatenate)           (None, 12, 12, 768)  0           ['activation_26[0][0]',          \n","                                                                  'activation_29[0][0]',          \n","                                                                  'max_pooling2d_2[0][0]']        \n","                                                                                                  \n"," conv2d_34 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n","                                                                                                  \n"," batch_normalization_34 (BatchN  (None, 12, 12, 128)  384        ['conv2d_34[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_34 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_34[0][0]'] \n","                                                                                                  \n"," conv2d_35 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_34[0][0]']          \n","                                                                                                  \n"," batch_normalization_35 (BatchN  (None, 12, 12, 128)  384        ['conv2d_35[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_35 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_35[0][0]'] \n","                                                                                                  \n"," conv2d_31 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n","                                                                                                  \n"," conv2d_36 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_35[0][0]']          \n","                                                                                                  \n"," batch_normalization_31 (BatchN  (None, 12, 12, 128)  384        ['conv2d_31[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_36 (BatchN  (None, 12, 12, 128)  384        ['conv2d_36[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_31 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_31[0][0]'] \n","                                                                                                  \n"," activation_36 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_36[0][0]'] \n","                                                                                                  \n"," conv2d_32 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_31[0][0]']          \n","                                                                                                  \n"," conv2d_37 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_36[0][0]']          \n","                                                                                                  \n"," batch_normalization_32 (BatchN  (None, 12, 12, 128)  384        ['conv2d_32[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_37 (BatchN  (None, 12, 12, 128)  384        ['conv2d_37[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_32 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_32[0][0]'] \n","                                                                                                  \n"," activation_37 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_37[0][0]'] \n","                                                                                                  \n"," average_pooling2d_3 (AveragePo  (None, 12, 12, 768)  0          ['mixed3[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_30 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed3[0][0]']                 \n","                                                                                                  \n"," conv2d_33 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_32[0][0]']          \n","                                                                                                  \n"," conv2d_38 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_37[0][0]']          \n","                                                                                                  \n"," conv2d_39 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_3[0][0]']    \n","                                                                                                  \n"," batch_normalization_30 (BatchN  (None, 12, 12, 192)  576        ['conv2d_30[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_33 (BatchN  (None, 12, 12, 192)  576        ['conv2d_33[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_38 (BatchN  (None, 12, 12, 192)  576        ['conv2d_38[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_39 (BatchN  (None, 12, 12, 192)  576        ['conv2d_39[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_30 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_30[0][0]'] \n","                                                                                                  \n"," activation_33 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_33[0][0]'] \n","                                                                                                  \n"," activation_38 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_38[0][0]'] \n","                                                                                                  \n"," activation_39 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_39[0][0]'] \n","                                                                                                  \n"," mixed4 (Concatenate)           (None, 12, 12, 768)  0           ['activation_30[0][0]',          \n","                                                                  'activation_33[0][0]',          \n","                                                                  'activation_38[0][0]',          \n","                                                                  'activation_39[0][0]']          \n","                                                                                                  \n"," conv2d_44 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n","                                                                                                  \n"," batch_normalization_44 (BatchN  (None, 12, 12, 160)  480        ['conv2d_44[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_44 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_44[0][0]'] \n","                                                                                                  \n"," conv2d_45 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_44[0][0]']          \n","                                                                                                  \n"," batch_normalization_45 (BatchN  (None, 12, 12, 160)  480        ['conv2d_45[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_45 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_45[0][0]'] \n","                                                                                                  \n"," conv2d_41 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n","                                                                                                  \n"," conv2d_46 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_45[0][0]']          \n","                                                                                                  \n"," batch_normalization_41 (BatchN  (None, 12, 12, 160)  480        ['conv2d_41[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_46 (BatchN  (None, 12, 12, 160)  480        ['conv2d_46[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_41 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_41[0][0]'] \n","                                                                                                  \n"," activation_46 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_46[0][0]'] \n","                                                                                                  \n"," conv2d_42 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_41[0][0]']          \n","                                                                                                  \n"," conv2d_47 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_46[0][0]']          \n","                                                                                                  \n"," batch_normalization_42 (BatchN  (None, 12, 12, 160)  480        ['conv2d_42[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_47 (BatchN  (None, 12, 12, 160)  480        ['conv2d_47[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_42 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_42[0][0]'] \n","                                                                                                  \n"," activation_47 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_47[0][0]'] \n","                                                                                                  \n"," average_pooling2d_4 (AveragePo  (None, 12, 12, 768)  0          ['mixed4[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_40 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed4[0][0]']                 \n","                                                                                                  \n"," conv2d_43 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_42[0][0]']          \n","                                                                                                  \n"," conv2d_48 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_47[0][0]']          \n","                                                                                                  \n"," conv2d_49 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_4[0][0]']    \n","                                                                                                  \n"," batch_normalization_40 (BatchN  (None, 12, 12, 192)  576        ['conv2d_40[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_43 (BatchN  (None, 12, 12, 192)  576        ['conv2d_43[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_48 (BatchN  (None, 12, 12, 192)  576        ['conv2d_48[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_49 (BatchN  (None, 12, 12, 192)  576        ['conv2d_49[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_40 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_40[0][0]'] \n","                                                                                                  \n"," activation_43 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_43[0][0]'] \n","                                                                                                  \n"," activation_48 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_48[0][0]'] \n","                                                                                                  \n"," activation_49 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_49[0][0]'] \n","                                                                                                  \n"," mixed5 (Concatenate)           (None, 12, 12, 768)  0           ['activation_40[0][0]',          \n","                                                                  'activation_43[0][0]',          \n","                                                                  'activation_48[0][0]',          \n","                                                                  'activation_49[0][0]']          \n","                                                                                                  \n"," conv2d_54 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n","                                                                                                  \n"," batch_normalization_54 (BatchN  (None, 12, 12, 160)  480        ['conv2d_54[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_54 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_54[0][0]'] \n","                                                                                                  \n"," conv2d_55 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_54[0][0]']          \n","                                                                                                  \n"," batch_normalization_55 (BatchN  (None, 12, 12, 160)  480        ['conv2d_55[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_55 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_55[0][0]'] \n","                                                                                                  \n"," conv2d_51 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n","                                                                                                  \n"," conv2d_56 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_55[0][0]']          \n","                                                                                                  \n"," batch_normalization_51 (BatchN  (None, 12, 12, 160)  480        ['conv2d_51[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_56 (BatchN  (None, 12, 12, 160)  480        ['conv2d_56[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_51 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_51[0][0]'] \n","                                                                                                  \n"," activation_56 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_56[0][0]'] \n","                                                                                                  \n"," conv2d_52 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_51[0][0]']          \n","                                                                                                  \n"," conv2d_57 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_56[0][0]']          \n","                                                                                                  \n"," batch_normalization_52 (BatchN  (None, 12, 12, 160)  480        ['conv2d_52[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_57 (BatchN  (None, 12, 12, 160)  480        ['conv2d_57[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_52 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_52[0][0]'] \n","                                                                                                  \n"," activation_57 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_57[0][0]'] \n","                                                                                                  \n"," average_pooling2d_5 (AveragePo  (None, 12, 12, 768)  0          ['mixed5[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_50 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed5[0][0]']                 \n","                                                                                                  \n"," conv2d_53 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_52[0][0]']          \n","                                                                                                  \n"," conv2d_58 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_57[0][0]']          \n","                                                                                                  \n"," conv2d_59 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_5[0][0]']    \n","                                                                                                  \n"," batch_normalization_50 (BatchN  (None, 12, 12, 192)  576        ['conv2d_50[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_53 (BatchN  (None, 12, 12, 192)  576        ['conv2d_53[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_58 (BatchN  (None, 12, 12, 192)  576        ['conv2d_58[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_59 (BatchN  (None, 12, 12, 192)  576        ['conv2d_59[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_50 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_50[0][0]'] \n","                                                                                                  \n"," activation_53 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_53[0][0]'] \n","                                                                                                  \n"," activation_58 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_58[0][0]'] \n","                                                                                                  \n"," activation_59 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_59[0][0]'] \n","                                                                                                  \n"," mixed6 (Concatenate)           (None, 12, 12, 768)  0           ['activation_50[0][0]',          \n","                                                                  'activation_53[0][0]',          \n","                                                                  'activation_58[0][0]',          \n","                                                                  'activation_59[0][0]']          \n","                                                                                                  \n"," conv2d_64 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n","                                                                                                  \n"," batch_normalization_64 (BatchN  (None, 12, 12, 192)  576        ['conv2d_64[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_64 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_64[0][0]'] \n","                                                                                                  \n"," conv2d_65 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_64[0][0]']          \n","                                                                                                  \n"," batch_normalization_65 (BatchN  (None, 12, 12, 192)  576        ['conv2d_65[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_65 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_65[0][0]'] \n","                                                                                                  \n"," conv2d_61 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n","                                                                                                  \n"," conv2d_66 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_65[0][0]']          \n","                                                                                                  \n"," batch_normalization_61 (BatchN  (None, 12, 12, 192)  576        ['conv2d_61[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_66 (BatchN  (None, 12, 12, 192)  576        ['conv2d_66[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_61 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_61[0][0]'] \n","                                                                                                  \n"," activation_66 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_66[0][0]'] \n","                                                                                                  \n"," conv2d_62 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_61[0][0]']          \n","                                                                                                  \n"," conv2d_67 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_66[0][0]']          \n","                                                                                                  \n"," batch_normalization_62 (BatchN  (None, 12, 12, 192)  576        ['conv2d_62[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_67 (BatchN  (None, 12, 12, 192)  576        ['conv2d_67[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_62 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_62[0][0]'] \n","                                                                                                  \n"," activation_67 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_67[0][0]'] \n","                                                                                                  \n"," average_pooling2d_6 (AveragePo  (None, 12, 12, 768)  0          ['mixed6[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_60 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n","                                                                                                  \n"," conv2d_63 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_62[0][0]']          \n","                                                                                                  \n"," conv2d_68 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_67[0][0]']          \n","                                                                                                  \n"," conv2d_69 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_6[0][0]']    \n","                                                                                                  \n"," batch_normalization_60 (BatchN  (None, 12, 12, 192)  576        ['conv2d_60[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_63 (BatchN  (None, 12, 12, 192)  576        ['conv2d_63[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_68 (BatchN  (None, 12, 12, 192)  576        ['conv2d_68[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_69 (BatchN  (None, 12, 12, 192)  576        ['conv2d_69[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_60 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_60[0][0]'] \n","                                                                                                  \n"," activation_63 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_63[0][0]'] \n","                                                                                                  \n"," activation_68 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_68[0][0]'] \n","                                                                                                  \n"," activation_69 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_69[0][0]'] \n","                                                                                                  \n"," mixed7 (Concatenate)           (None, 12, 12, 768)  0           ['activation_60[0][0]',          \n","                                                                  'activation_63[0][0]',          \n","                                                                  'activation_68[0][0]',          \n","                                                                  'activation_69[0][0]']          \n","                                                                                                  \n"," conv2d_72 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n","                                                                                                  \n"," batch_normalization_72 (BatchN  (None, 12, 12, 192)  576        ['conv2d_72[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_72 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_72[0][0]'] \n","                                                                                                  \n"," conv2d_73 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_72[0][0]']          \n","                                                                                                  \n"," batch_normalization_73 (BatchN  (None, 12, 12, 192)  576        ['conv2d_73[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_73 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_73[0][0]'] \n","                                                                                                  \n"," conv2d_70 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n","                                                                                                  \n"," conv2d_74 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_73[0][0]']          \n","                                                                                                  \n"," batch_normalization_70 (BatchN  (None, 12, 12, 192)  576        ['conv2d_70[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_74 (BatchN  (None, 12, 12, 192)  576        ['conv2d_74[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_70 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_70[0][0]'] \n","                                                                                                  \n"," activation_74 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_74[0][0]'] \n","                                                                                                  \n"," conv2d_71 (Conv2D)             (None, 5, 5, 320)    552960      ['activation_70[0][0]']          \n","                                                                                                  \n"," conv2d_75 (Conv2D)             (None, 5, 5, 192)    331776      ['activation_74[0][0]']          \n","                                                                                                  \n"," batch_normalization_71 (BatchN  (None, 5, 5, 320)   960         ['conv2d_71[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_75 (BatchN  (None, 5, 5, 192)   576         ['conv2d_75[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_71 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_71[0][0]'] \n","                                                                                                  \n"," activation_75 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_75[0][0]'] \n","                                                                                                  \n"," max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)   0           ['mixed7[0][0]']                 \n","                                                                                                  \n"," mixed8 (Concatenate)           (None, 5, 5, 1280)   0           ['activation_71[0][0]',          \n","                                                                  'activation_75[0][0]',          \n","                                                                  'max_pooling2d_3[0][0]']        \n","                                                                                                  \n"," conv2d_80 (Conv2D)             (None, 5, 5, 448)    573440      ['mixed8[0][0]']                 \n","                                                                                                  \n"," batch_normalization_80 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_80[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_80 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_80[0][0]'] \n","                                                                                                  \n"," conv2d_77 (Conv2D)             (None, 5, 5, 384)    491520      ['mixed8[0][0]']                 \n","                                                                                                  \n"," conv2d_81 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_80[0][0]']          \n","                                                                                                  \n"," batch_normalization_77 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_77[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_81 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_81[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_77 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_77[0][0]'] \n","                                                                                                  \n"," activation_81 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_81[0][0]'] \n","                                                                                                  \n"," conv2d_78 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n","                                                                                                  \n"," conv2d_79 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n","                                                                                                  \n"," conv2d_82 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n","                                                                                                  \n"," conv2d_83 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n","                                                                                                  \n"," average_pooling2d_7 (AveragePo  (None, 5, 5, 1280)  0           ['mixed8[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_76 (Conv2D)             (None, 5, 5, 320)    409600      ['mixed8[0][0]']                 \n","                                                                                                  \n"," batch_normalization_78 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_78[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_79 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_79[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_82 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_82[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_83 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_83[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv2d_84 (Conv2D)             (None, 5, 5, 192)    245760      ['average_pooling2d_7[0][0]']    \n","                                                                                                  \n"," batch_normalization_76 (BatchN  (None, 5, 5, 320)   960         ['conv2d_76[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_78 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_78[0][0]'] \n","                                                                                                  \n"," activation_79 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_79[0][0]'] \n","                                                                                                  \n"," activation_82 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_82[0][0]'] \n","                                                                                                  \n"," activation_83 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_83[0][0]'] \n","                                                                                                  \n"," batch_normalization_84 (BatchN  (None, 5, 5, 192)   576         ['conv2d_84[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_76 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_76[0][0]'] \n","                                                                                                  \n"," mixed9_0 (Concatenate)         (None, 5, 5, 768)    0           ['activation_78[0][0]',          \n","                                                                  'activation_79[0][0]']          \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 5, 5, 768)    0           ['activation_82[0][0]',          \n","                                                                  'activation_83[0][0]']          \n","                                                                                                  \n"," activation_84 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_84[0][0]'] \n","                                                                                                  \n"," mixed9 (Concatenate)           (None, 5, 5, 2048)   0           ['activation_76[0][0]',          \n","                                                                  'mixed9_0[0][0]',               \n","                                                                  'concatenate[0][0]',            \n","                                                                  'activation_84[0][0]']          \n","                                                                                                  \n"," conv2d_89 (Conv2D)             (None, 5, 5, 448)    917504      ['mixed9[0][0]']                 \n","                                                                                                  \n"," batch_normalization_89 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_89[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_89 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_89[0][0]'] \n","                                                                                                  \n"," conv2d_86 (Conv2D)             (None, 5, 5, 384)    786432      ['mixed9[0][0]']                 \n","                                                                                                  \n"," conv2d_90 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_89[0][0]']          \n","                                                                                                  \n"," batch_normalization_86 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_86[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_90 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_90[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_86 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_86[0][0]'] \n","                                                                                                  \n"," activation_90 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_90[0][0]'] \n","                                                                                                  \n"," conv2d_87 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n","                                                                                                  \n"," conv2d_88 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n","                                                                                                  \n"," conv2d_91 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n","                                                                                                  \n"," conv2d_92 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n","                                                                                                  \n"," average_pooling2d_8 (AveragePo  (None, 5, 5, 2048)  0           ['mixed9[0][0]']                 \n"," oling2D)                                                                                         \n","                                                                                                  \n"," conv2d_85 (Conv2D)             (None, 5, 5, 320)    655360      ['mixed9[0][0]']                 \n","                                                                                                  \n"," batch_normalization_87 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_87[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_88 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_88[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_91 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_91[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," batch_normalization_92 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_92[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," conv2d_93 (Conv2D)             (None, 5, 5, 192)    393216      ['average_pooling2d_8[0][0]']    \n","                                                                                                  \n"," batch_normalization_85 (BatchN  (None, 5, 5, 320)   960         ['conv2d_85[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_87 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_87[0][0]'] \n","                                                                                                  \n"," activation_88 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_88[0][0]'] \n","                                                                                                  \n"," activation_91 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_91[0][0]'] \n","                                                                                                  \n"," activation_92 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_92[0][0]'] \n","                                                                                                  \n"," batch_normalization_93 (BatchN  (None, 5, 5, 192)   576         ['conv2d_93[0][0]']              \n"," ormalization)                                                                                    \n","                                                                                                  \n"," activation_85 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_85[0][0]'] \n","                                                                                                  \n"," mixed9_1 (Concatenate)         (None, 5, 5, 768)    0           ['activation_87[0][0]',          \n","                                                                  'activation_88[0][0]']          \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, 5, 5, 768)    0           ['activation_91[0][0]',          \n","                                                                  'activation_92[0][0]']          \n","                                                                                                  \n"," activation_93 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_93[0][0]'] \n","                                                                                                  \n"," mixed10 (Concatenate)          (None, 5, 5, 2048)   0           ['activation_85[0][0]',          \n","                                                                  'mixed9_1[0][0]',               \n","                                                                  'concatenate_1[0][0]',          \n","                                                                  'activation_93[0][0]']          \n","                                                                                                  \n","==================================================================================================\n","Total params: 21,802,784\n","Trainable params: 0\n","Non-trainable params: 21,802,784\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"YE0OMpzD3_0n"},"source":["## Now using LSTM to generate title"]},{"cell_type":"code","metadata":{"id":"DGwKTwZ-4r-G","executionInfo":{"status":"ok","timestamp":1638597794900,"user_tz":-300,"elapsed":2820,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}}},"source":["import tensorflow as tf\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.layers import Embedding, LSTM, Dense, Dropout\n","from keras.preprocessing.text import Tokenizer\n","from keras.callbacks import EarlyStopping\n","from keras.models import Sequential\n","import tensorflow.keras.utils as ku \n","\n","\n","from tensorflow.random import set_seed\n","from numpy.random import seed\n","set_seed(2)\n","seed(1)\n","\n","import os\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","warnings.simplefilter(action='ignore', category=FutureWarning)"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"VBFRKCdi4QeI","executionInfo":{"status":"ok","timestamp":1638597799411,"user_tz":-300,"elapsed":365,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}}},"source":["with open('/content/drive/MyDrive/Titles.txt', encoding=\"UTF-8\") as file:\n","    data = file.read()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"COAn2oxa5XOI","executionInfo":{"status":"ok","timestamp":1638597805814,"user_tz":-300,"elapsed":381,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}}},"source":["import string\n","def clean_text(data):\n","    \"\"\"\n","    Removes non essential characters in corpus of text\n","    \"\"\"\n","    data = \"\".join(v for v in data if v not in string.punctuation).lower()\n","    data = data.encode(\"utf8\").decode(\"ascii\",'ignore')\n","    return data"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZDmEt7egBsWj","executionInfo":{"status":"ok","timestamp":1638597813193,"user_tz":-300,"elapsed":386,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"ae5783d0-f2a2-47e3-d8cf-34277498a660"},"source":["cleaned = clean_text(data)\n","print(cleaned[:5])"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["sciki\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0NIfbfF52jF","executionInfo":{"status":"ok","timestamp":1638597817378,"user_tz":-300,"elapsed":364,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"0e633e87-4309-409e-e062-a3e7de363873"},"source":["corpus = cleaned.split(\"\\n\")\n","print(corpus[:10])"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["['scikitlearn machine learning in python', 'pattern recognition and machine learning', 'gaussian processes in machine learning', 'machine learning in automated text categorization', 'machine learning', 'thumbs up sentiment classification using machine learning techniques', 'ensemble methods in machine learning', 'c4 5 programs for machine learning', 'uci machine learning repository', 'data mining practical machine learning tools and techniques']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vQdPwx9N5-U3","executionInfo":{"status":"ok","timestamp":1638597822227,"user_tz":-300,"elapsed":589,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"118a38f6-45e6-4b9d-b0cd-5cd944843bdc"},"source":["tokenizer = Tokenizer()\n","\n","def get_sequence_of_tokens(corpus):\n","    ## tokenization\n","    tokenizer.fit_on_texts(corpus)\n","    total_words = len(tokenizer.word_index) + 1\n","    \n","    ## convert data to sequence of tokens \n","    input_sequences = []\n","    for line in corpus:\n","        token_list = tokenizer.texts_to_sequences([line])[0]\n","        for i in range(1, len(token_list)):\n","            n_gram_sequence = token_list[:i+1]\n","            input_sequences.append(n_gram_sequence)\n","    return input_sequences, total_words\n","\n","inp_sequences, total_words = get_sequence_of_tokens(corpus)\n","print(total_words)\n","inp_sequences[:10]"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["1840\n"]},{"output_type":"execute_result","data":{"text/plain":["[[161, 2],\n"," [161, 2, 1],\n"," [161, 2, 1, 7],\n"," [161, 2, 1, 7, 137],\n"," [162, 42],\n"," [162, 42, 4],\n"," [162, 42, 4, 2],\n"," [162, 42, 4, 2, 1],\n"," [138, 163],\n"," [138, 163, 7]]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j4wzjWJu6TpZ","executionInfo":{"status":"ok","timestamp":1638597825433,"user_tz":-300,"elapsed":363,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"12699f67-541f-47da-935b-66d64e85dc06"},"source":["import numpy as np\n","import tensorflow.keras.utils as ku \n","\n","def generate_padded_sequences(input_sequences):\n","    max_sequence_len = max([len(x) for x in input_sequences])\n","    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n","    \n","    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n","    label = ku.to_categorical(label, num_classes=total_words)\n","    return predictors, label, max_sequence_len\n","\n","predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)\n","print(max_sequence_len)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["21\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tWQatK_u6xcA","executionInfo":{"status":"ok","timestamp":1638597829444,"user_tz":-300,"elapsed":596,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"8cbdcfd4-e7a1-4aa6-9247-cb0e4f3678bf"},"source":["def create_model(max_sequence_len, total_words):\n","    input_len = max_sequence_len - 1\n","    model = Sequential()\n","    \n","    # Add Input Embedding Layer\n","    model.add(Embedding(total_words, 10, input_length=input_len))\n","    \n","    # Add Hidden Layer 1 - LSTM Layer\n","    model.add(LSTM(100))\n","    model.add(Dropout(0.1))\n","    \n","    # Add Output Layer\n","    model.add(Dense(total_words, activation='softmax'))\n","\n","    model.compile(loss='categorical_crossentropy', optimizer='adam')\n","    \n","    return model\n","\n","lstm_model = create_model(max_sequence_len, total_words)\n","lstm_model.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 20, 10)            18400     \n","                                                                 \n"," lstm (LSTM)                 (None, 100)               44400     \n","                                                                 \n"," dropout (Dropout)           (None, 100)               0         \n","                                                                 \n"," dense (Dense)               (None, 1840)              185840    \n","                                                                 \n","=================================================================\n","Total params: 248,640\n","Trainable params: 248,640\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UjJfl8KM7RLR","executionInfo":{"status":"ok","timestamp":1638596333698,"user_tz":-300,"elapsed":418190,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"9d873112-2e0d-4d24-c45b-6d3f3a55c0c4"},"source":["lstm_model.fit(predictors, label, epochs=100, verbose=5)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","Epoch 2/100\n","Epoch 3/100\n","Epoch 4/100\n","Epoch 5/100\n","Epoch 6/100\n","Epoch 7/100\n","Epoch 8/100\n","Epoch 9/100\n","Epoch 10/100\n","Epoch 11/100\n","Epoch 12/100\n","Epoch 13/100\n","Epoch 14/100\n","Epoch 15/100\n","Epoch 16/100\n","Epoch 17/100\n","Epoch 18/100\n","Epoch 19/100\n","Epoch 20/100\n","Epoch 21/100\n","Epoch 22/100\n","Epoch 23/100\n","Epoch 24/100\n","Epoch 25/100\n","Epoch 26/100\n","Epoch 27/100\n","Epoch 28/100\n","Epoch 29/100\n","Epoch 30/100\n","Epoch 31/100\n","Epoch 32/100\n","Epoch 33/100\n","Epoch 34/100\n","Epoch 35/100\n","Epoch 36/100\n","Epoch 37/100\n","Epoch 38/100\n","Epoch 39/100\n","Epoch 40/100\n","Epoch 41/100\n","Epoch 42/100\n","Epoch 43/100\n","Epoch 44/100\n","Epoch 45/100\n","Epoch 46/100\n","Epoch 47/100\n","Epoch 48/100\n","Epoch 49/100\n","Epoch 50/100\n","Epoch 51/100\n","Epoch 52/100\n","Epoch 53/100\n","Epoch 54/100\n","Epoch 55/100\n","Epoch 56/100\n","Epoch 57/100\n","Epoch 58/100\n","Epoch 59/100\n","Epoch 60/100\n","Epoch 61/100\n","Epoch 62/100\n","Epoch 63/100\n","Epoch 64/100\n","Epoch 65/100\n","Epoch 66/100\n","Epoch 67/100\n","Epoch 68/100\n","Epoch 69/100\n","Epoch 70/100\n","Epoch 71/100\n","Epoch 72/100\n","Epoch 73/100\n","Epoch 74/100\n","Epoch 75/100\n","Epoch 76/100\n","Epoch 77/100\n","Epoch 78/100\n","Epoch 79/100\n","Epoch 80/100\n","Epoch 81/100\n","Epoch 82/100\n","Epoch 83/100\n","Epoch 84/100\n","Epoch 85/100\n","Epoch 86/100\n","Epoch 87/100\n","Epoch 88/100\n","Epoch 89/100\n","Epoch 90/100\n","Epoch 91/100\n","Epoch 92/100\n","Epoch 93/100\n","Epoch 94/100\n","Epoch 95/100\n","Epoch 96/100\n","Epoch 97/100\n","Epoch 98/100\n","Epoch 99/100\n","Epoch 100/100\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fecd210e290>"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"4j4aKkxX7kbN","executionInfo":{"status":"ok","timestamp":1638597836137,"user_tz":-300,"elapsed":371,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}}},"source":["lstm_model.save('/content/drive/MyDrive/title_model.h5')"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"on_ARLZ6_XWm","executionInfo":{"status":"ok","timestamp":1638597838735,"user_tz":-300,"elapsed":365,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}}},"source":["from keras.models import load_model\n","\n","model = load_model('/content/drive/MyDrive/title_model.h5')"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"jIKh-Xfu7WzK","executionInfo":{"status":"ok","timestamp":1638603346296,"user_tz":-300,"elapsed":443,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}}},"source":["def generate_text(seed_text, next_words, model, max_sequence_len):\n","    for _ in range(next_words):\n","        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","        # print(token_list)\n","\n","        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","        # print(token_list)\n","        predicted = model.predict(token_list, verbose=0) # y_predict = np.argmax(model.predict(x_test), axis=-1)\n","        # print(predicted)\n","        pre = np.argmax(predicted)\n","        # print(pre)\n","        \n","        output_word = \"\"\n","        for word,index in tokenizer.word_index.items():\n","        #   print(word, index)\n","          if index == pre:\n","              output_word = word\n","              break\n","        seed_text += \" \"+output_word\n","    return seed_text.title()"],"execution_count":84,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VI_bzuiG7fGM","executionInfo":{"status":"ok","timestamp":1638603370480,"user_tz":-300,"elapsed":3535,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"596d661a-ae55-4ea1-88aa-9729aa0905bb"},"source":["print(generate_text(\"\", 5, lstm_model, max_sequence_len))\n","print(generate_text(\"euclidean\", 4, lstm_model, max_sequence_len))\n","print(generate_text(\"generative\", 5, model, max_sequence_len))\n","print(generate_text(\"ground breaking\", 5, lstm_model, max_sequence_len))\n","print(generate_text(\"new\", 4, lstm_model, max_sequence_len))\n","# print(generate_text(\"understanding\", 5, lstm_model, max_sequence_len))\n","print(generate_text(\"long short term memory\", 6, lstm_model, max_sequence_len))\n","print(generate_text(\"LSTM\", 6, lstm_model, max_sequence_len))\n","print(generate_text(\"a\", 5, lstm_model, max_sequence_len))\n","print(generate_text(\"anomaly\", 5, lstm_model, max_sequence_len))\n","print(generate_text(\"data\", 7, lstm_model, max_sequence_len))\n","print(generate_text(\"designing\", 7, lstm_model, max_sequence_len))\n","print(generate_text(\"reinforcement\", 7, lstm_model, max_sequence_len))"],"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":[" 101 Gcc Combining Infrared Tomography\n","Euclidean 101 Gcc Combining Infrared\n","Generative Combined Flare Flare Combining Combining\n","Ground Breaking 101 Gcc Combining Infrared Tomography\n","New Flare Combining Combining Expression\n","Long Short Term Memory 101 Market Combined Flare Market Lowcost\n","Lstm Flare Market Flare Market Deploying Combining\n","A 101 Market 101 Gcc Infrared\n","Anomaly Flare Market Market Combined Flare\n","Data Combined Flare Combining Combining Discrimination Discrimination Genedisease\n","Designing 101 Gcc Combining Infrared Tomography Deploying Deploying\n","Reinforcement Flare Combining Combining Expression Discrimination Genedisease Genedisease\n"]}]},{"cell_type":"code","metadata":{"id":"RzUqSZMp7fRX","executionInfo":{"status":"ok","timestamp":1638610039755,"user_tz":-300,"elapsed":369,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}}},"source":["def generate_text11(seed_text, next_words, model, max_sequence_len):\n","    for _ in range(next_words):\n","        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","        # print(token_list)\n","\n","        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","        # print(token_list)\n","        predicted = model.predict(token_list == 0.99, verbose=0).astype('int32') # y_predict = np.argmax(model.predict(x_test), axis=-1)\n","        # print(predicted)\n","        pre = np.argmax(predicted)\n","        # print(pre)\n","        \n","        output_word = \"\"\n","        for word,index in tokenizer.word_index.items():\n","        #   print(word, index)\n","          if index == pre:\n","              output_word = word\n","              break\n","        seed_text += \" \"+output_word\n","    return seed_text.title()"],"execution_count":101,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z6loVksAYv22","executionInfo":{"status":"ok","timestamp":1638610109593,"user_tz":-300,"elapsed":967,"user":{"displayName":"bilal iqbal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhaY1FCz-7NJsrALbxr4UM7V-7tHh4FDMNNc7Sn8w=s64","userId":"11700761488017837942"}},"outputId":"011d6a7c-6dce-4ccb-8a9d-72710e2da03d"},"source":["print(generate_text11(\"python\", 5, lstm_model, max_sequence_len))\n","print(generate_text11(\"falcon\", 7, lstm_model, max_sequence_len))"],"execution_count":103,"outputs":[{"output_type":"stream","name":"stdout","text":["Python     \n","Falcon       \n"]}]},{"cell_type":"code","metadata":{"id":"cOgQKk0FYv7d"},"source":["from keras.callbacks import EarlyStopping, "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qa0OngVeYwFq"},"source":[""],"execution_count":null,"outputs":[]}]}